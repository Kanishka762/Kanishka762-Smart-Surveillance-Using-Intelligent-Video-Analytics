2023/07/06 06:58:29 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.8.16 (default, Jun 12 2023, 18:09:05) [GCC 11.2.0]
    CUDA available: True
    numpy_random_seed: 1170670265
    GPU 0,1: NVIDIA A40
    CUDA_HOME: /usr
    NVCC: Cuda compilation tools, release 10.1, V10.1.24
    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0
    PyTorch: 2.0.1+cu117
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.15.2+cu117
    OpenCV: 4.7.0
    MMEngine: 0.8.0

Runtime environment:
    cudnn_benchmark: False
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 1170670265
    diff_rank_seed: False
    deterministic: False
    Distributed launcher: pytorch
    Distributed training: True
    GPU number: 2
------------------------------------------------------------

2023/07/06 06:58:30 - mmengine - INFO - Config:
default_scope = 'mmaction'
default_hooks = dict(
    runtime_info=dict(type='RuntimeInfoHook'),
    timer=dict(type='IterTimerHook'),
    logger=dict(type='LoggerHook', interval=20, ignore_last=False),
    param_scheduler=dict(type='ParamSchedulerHook'),
    checkpoint=dict(type='CheckpointHook', interval=1, save_best='auto'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    sync_buffers=dict(type='SyncBuffersHook'))
env_cfg = dict(
    cudnn_benchmark=False,
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0),
    dist_cfg=dict(backend='nccl'))
log_processor = dict(type='LogProcessor', window_size=20, by_epoch=True)
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    type='ActionVisualizer', vis_backends=[
        dict(type='LocalVisBackend'),
    ])
log_level = 'INFO'
load_from = None
resume = False
url = 'https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth'
model = dict(
    type='FastRCNN',
    _scope_='mmdet',
    init_cfg=dict(
        type='Pretrained',
        checkpoint=
        'https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth'
    ),
    backbone=dict(
        type='mmaction.ResNet3dSlowFast',
        pretrained=None,
        resample_rate=8,
        speed_ratio=8,
        channel_ratio=8,
        slow_pathway=dict(
            type='resnet3d',
            depth=50,
            pretrained=None,
            lateral=True,
            conv1_kernel=(
                1,
                7,
                7,
            ),
            dilations=(
                1,
                1,
                1,
                1,
            ),
            conv1_stride_t=1,
            pool1_stride_t=1,
            inflate=(
                0,
                0,
                1,
                1,
            ),
            spatial_strides=(
                1,
                2,
                2,
                1,
            )),
        fast_pathway=dict(
            type='resnet3d',
            depth=50,
            pretrained=None,
            lateral=False,
            base_channels=8,
            conv1_kernel=(
                5,
                7,
                7,
            ),
            conv1_stride_t=1,
            pool1_stride_t=1,
            spatial_strides=(
                1,
                2,
                2,
                1,
            ))),
    roi_head=dict(
        type='AVARoIHead',
        bbox_roi_extractor=dict(
            type='SingleRoIExtractor3D',
            roi_layer_type='RoIAlign',
            output_size=8,
            with_temporal_pool=True),
        bbox_head=dict(
            type='BBoxHeadAVA',
            in_channels=2304,
            num_classes=81,
            multilabel=True,
            dropout_ratio=0.5)),
    data_preprocessor=dict(
        type='mmaction.ActionDataPreprocessor',
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        std=[
            58.395,
            57.12,
            57.375,
        ],
        format_shape='NCTHW'),
    train_cfg=dict(
        rcnn=dict(
            assigner=dict(
                type='MaxIoUAssignerAVA',
                pos_iou_thr=0.9,
                neg_iou_thr=0.9,
                min_pos_iou=0.9),
            sampler=dict(
                type='RandomSampler',
                num=32,
                pos_fraction=1,
                neg_pos_ub=-1,
                add_gt_as_proposals=True),
            pos_weight=1.0)),
    test_cfg=dict(rcnn=None))
dataset_type = 'AVADataset'
data_root = '../mmaction2_v1.0/data/ava/rawframes'
anno_root = '../mmaction2_v1.0/data/ava/annotations'
ann_file_train = '../mmaction2_v1.0/data/ava/annotations/ava_custom_train_v2.2.csv'
ann_file_val = '../mmaction2_v1.0/data/ava/annotations/ava_custom_val_v2.2.csv'
exclude_file_train = '../mmaction2_v1.0/data/ava/annotations/ava_train_excluded_timestamps_v2.2.csv'
exclude_file_val = '../mmaction2_v1.0/data/ava/annotations/ava_val_excluded_timestamps_v2.2.csv'
label_file = '../mmaction2_v1.0/data/ava/annotations/ava_action_list_v2.2_for_activitynet_2019.pbtxt'
proposal_file_train = '../mmaction2_v1.0/data/ava/annotations/ava_dense_proposals_train.FAIR.recall_93.9.pkl'
proposal_file_val = '../mmaction2_v1.0/data/ava/annotations/ava_dense_proposals_val.FAIR.recall_93.9.pkl'
file_client_args = dict(io_backend='disk')
train_pipeline = [
    dict(type='SampleAVAFrames', clip_len=32, frame_interval=2),
    dict(type='RawFrameDecode', io_backend='disk'),
    dict(type='RandomRescale', scale_range=(
        256,
        320,
    )),
    dict(type='RandomCrop', size=256),
    dict(type='Flip', flip_ratio=0.5),
    dict(type='FormatShape', input_format='NCTHW', collapse=True),
    dict(type='PackActionInputs'),
]
val_pipeline = [
    dict(
        type='SampleAVAFrames', clip_len=32, frame_interval=2, test_mode=True),
    dict(type='RawFrameDecode', io_backend='disk'),
    dict(type='Resize', scale=(
        -1,
        256,
    )),
    dict(type='FormatShape', input_format='NCTHW', collapse=True),
    dict(type='PackActionInputs'),
]
train_dataloader = dict(
    batch_size=16,
    num_workers=8,
    persistent_workers=True,
    sampler=dict(type='DefaultSampler', shuffle=True),
    dataset=dict(
        type='AVADataset',
        ann_file=
        '../mmaction2_v1.0/data/ava/annotations/ava_custom_train_v2.2.csv',
        exclude_file=
        '../mmaction2_v1.0/data/ava/annotations/ava_train_excluded_timestamps_v2.2.csv',
        pipeline=[
            dict(type='SampleAVAFrames', clip_len=32, frame_interval=2),
            dict(type='RawFrameDecode', io_backend='disk'),
            dict(type='RandomRescale', scale_range=(
                256,
                320,
            )),
            dict(type='RandomCrop', size=256),
            dict(type='Flip', flip_ratio=0.5),
            dict(type='FormatShape', input_format='NCTHW', collapse=True),
            dict(type='PackActionInputs'),
        ],
        label_file=
        '../mmaction2_v1.0/data/ava/annotations/ava_action_list_v2.2_for_activitynet_2019.pbtxt',
        proposal_file=
        '../mmaction2_v1.0/data/ava/annotations/ava_dense_proposals_train.FAIR.recall_93.9.pkl',
        data_prefix=dict(img='../mmaction2_v1.0/data/ava/rawframes')))
val_dataloader = dict(
    batch_size=1,
    num_workers=8,
    persistent_workers=True,
    sampler=dict(type='DefaultSampler', shuffle=False),
    dataset=dict(
        type='AVADataset',
        ann_file=
        '../mmaction2_v1.0/data/ava/annotations/ava_custom_val_v2.2.csv',
        exclude_file=
        '../mmaction2_v1.0/data/ava/annotations/ava_val_excluded_timestamps_v2.2.csv',
        pipeline=[
            dict(
                type='SampleAVAFrames',
                clip_len=32,
                frame_interval=2,
                test_mode=True),
            dict(type='RawFrameDecode', io_backend='disk'),
            dict(type='Resize', scale=(
                -1,
                256,
            )),
            dict(type='FormatShape', input_format='NCTHW', collapse=True),
            dict(type='PackActionInputs'),
        ],
        label_file=
        '../mmaction2_v1.0/data/ava/annotations/ava_action_list_v2.2_for_activitynet_2019.pbtxt',
        proposal_file=
        '../mmaction2_v1.0/data/ava/annotations/ava_dense_proposals_val.FAIR.recall_93.9.pkl',
        data_prefix=dict(img='../mmaction2_v1.0/data/ava/rawframes'),
        test_mode=True))
test_dataloader = dict(
    batch_size=1,
    num_workers=8,
    persistent_workers=True,
    sampler=dict(type='DefaultSampler', shuffle=False),
    dataset=dict(
        type='AVADataset',
        ann_file=
        '../mmaction2_v1.0/data/ava/annotations/ava_custom_val_v2.2.csv',
        exclude_file=
        '../mmaction2_v1.0/data/ava/annotations/ava_val_excluded_timestamps_v2.2.csv',
        pipeline=[
            dict(
                type='SampleAVAFrames',
                clip_len=32,
                frame_interval=2,
                test_mode=True),
            dict(type='RawFrameDecode', io_backend='disk'),
            dict(type='Resize', scale=(
                -1,
                256,
            )),
            dict(type='FormatShape', input_format='NCTHW', collapse=True),
            dict(type='PackActionInputs'),
        ],
        label_file=
        '../mmaction2_v1.0/data/ava/annotations/ava_action_list_v2.2_for_activitynet_2019.pbtxt',
        proposal_file=
        '../mmaction2_v1.0/data/ava/annotations/ava_dense_proposals_val.FAIR.recall_93.9.pkl',
        data_prefix=dict(img='../mmaction2_v1.0/data/ava/rawframes'),
        test_mode=True))
val_evaluator = dict(
    type='AVAMetric',
    ann_file='../mmaction2_v1.0/data/ava/annotations/ava_custom_val_v2.2.csv',
    label_file=
    '../mmaction2_v1.0/data/ava/annotations/ava_action_list_v2.2_for_activitynet_2019.pbtxt',
    exclude_file=
    '../mmaction2_v1.0/data/ava/annotations/ava_val_excluded_timestamps_v2.2.csv'
)
test_evaluator = dict(
    type='AVAMetric',
    ann_file='../mmaction2_v1.0/data/ava/annotations/ava_custom_val_v2.2.csv',
    label_file=
    '../mmaction2_v1.0/data/ava/annotations/ava_action_list_v2.2_for_activitynet_2019.pbtxt',
    exclude_file=
    '../mmaction2_v1.0/data/ava/annotations/ava_val_excluded_timestamps_v2.2.csv'
)
train_cfg = dict(
    type='EpochBasedTrainLoop', max_epochs=20, val_begin=1, val_interval=1)
val_cfg = dict(type='ValLoop')
test_cfg = dict(type='TestLoop')
param_scheduler = [
    dict(type='LinearLR', start_factor=0.1, by_epoch=True, begin=0, end=5),
    dict(
        type='MultiStepLR',
        begin=0,
        end=20,
        by_epoch=True,
        milestones=[
            10,
            15,
        ],
        gamma=0.1),
]
optim_wrapper = dict(
    optimizer=dict(type='SGD', lr=0.2, momentum=0.9, weight_decay=1e-05),
    clip_grad=dict(max_norm=40, norm_type=2))
auto_scale_lr = dict(enable=False, base_batch_size=128)
launcher = 'pytorch'
work_dir = './work_dirs/slowfast_kinetics400-pretrained-r50_8xb16-4x16x1-20e_ava21-rgb'
randomness = dict(seed=None, diff_rank_seed=False, deterministic=False)

2023/07/06 06:58:34 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SyncBuffersHook                    
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SyncBuffersHook                    
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train:
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
2023/07/06 06:58:37 - mmengine - INFO - 12224 out of 12224 frames are valid.
2023/07/06 06:58:38 - mmengine - INFO - 3316 out of 3316 frames are valid.
2023/07/06 06:58:40 - mmengine - INFO - load model from: https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth
2023/07/06 06:58:40 - mmengine - INFO - Loads checkpoint by http backend from path: https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth
2023/07/06 06:58:41 - mmengine - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: cls_head.fc_cls.weight, cls_head.fc_cls.bias

missing keys in source state_dict: roi_head.bbox_head.fc_cls.weight, roi_head.bbox_head.fc_cls.bias

Name of parameter - Initialization information

backbone.slow_path.conv1.conv.weight - torch.Size([64, 3, 1, 7, 7]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.conv1.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.conv1.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer1.0.conv1.conv.weight - torch.Size([64, 80, 1, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer1.0.conv1.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer1.0.conv1.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer1.0.conv2.conv.weight - torch.Size([64, 64, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer1.0.conv2.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer1.0.conv2.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer1.0.conv3.conv.weight - torch.Size([256, 64, 1, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer1.0.conv3.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer1.0.conv3.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer1.0.downsample.conv.weight - torch.Size([256, 80, 1, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer1.0.downsample.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer1.0.downsample.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer1.1.conv1.conv.weight - torch.Size([64, 256, 1, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer1.1.conv1.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer1.1.conv1.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer1.1.conv2.conv.weight - torch.Size([64, 64, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer1.1.conv2.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer1.1.conv2.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer1.1.conv3.conv.weight - torch.Size([256, 64, 1, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer1.1.conv3.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer1.1.conv3.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer1.2.conv1.conv.weight - torch.Size([64, 256, 1, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer1.2.conv1.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer1.2.conv1.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer1.2.conv2.conv.weight - torch.Size([64, 64, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer1.2.conv2.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer1.2.conv2.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer1.2.conv3.conv.weight - torch.Size([256, 64, 1, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer1.2.conv3.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer1.2.conv3.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer2.0.conv1.conv.weight - torch.Size([128, 320, 1, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer2.0.conv1.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer2.0.conv1.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer2.0.conv2.conv.weight - torch.Size([128, 128, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer2.0.conv2.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer2.0.conv2.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer2.0.conv3.conv.weight - torch.Size([512, 128, 1, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer2.0.conv3.bn.weight - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer2.0.conv3.bn.bias - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer2.0.downsample.conv.weight - torch.Size([512, 320, 1, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer2.0.downsample.bn.weight - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer2.0.downsample.bn.bias - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer2.1.conv1.conv.weight - torch.Size([128, 512, 1, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer2.1.conv1.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer2.1.conv1.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer2.1.conv2.conv.weight - torch.Size([128, 128, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer2.1.conv2.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer2.1.conv2.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer2.1.conv3.conv.weight - torch.Size([512, 128, 1, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer2.1.conv3.bn.weight - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer2.1.conv3.bn.bias - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer2.2.conv1.conv.weight - torch.Size([128, 512, 1, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer2.2.conv1.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer2.2.conv1.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer2.2.conv2.conv.weight - torch.Size([128, 128, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer2.2.conv2.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer2.2.conv2.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer2.2.conv3.conv.weight - torch.Size([512, 128, 1, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer2.2.conv3.bn.weight - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer2.2.conv3.bn.bias - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer2.3.conv1.conv.weight - torch.Size([128, 512, 1, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer2.3.conv1.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer2.3.conv1.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer2.3.conv2.conv.weight - torch.Size([128, 128, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer2.3.conv2.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer2.3.conv2.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer2.3.conv3.conv.weight - torch.Size([512, 128, 1, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer2.3.conv3.bn.weight - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer2.3.conv3.bn.bias - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.0.conv1.conv.weight - torch.Size([256, 640, 3, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.0.conv1.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.0.conv1.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.0.conv2.conv.weight - torch.Size([256, 256, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.0.conv2.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.0.conv2.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.0.conv3.conv.weight - torch.Size([1024, 256, 1, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.0.conv3.bn.weight - torch.Size([1024]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.0.conv3.bn.bias - torch.Size([1024]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.0.downsample.conv.weight - torch.Size([1024, 640, 1, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.0.downsample.bn.weight - torch.Size([1024]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.0.downsample.bn.bias - torch.Size([1024]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.1.conv1.conv.weight - torch.Size([256, 1024, 3, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.1.conv1.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.1.conv1.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.1.conv2.conv.weight - torch.Size([256, 256, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.1.conv2.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.1.conv2.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.1.conv3.conv.weight - torch.Size([1024, 256, 1, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.1.conv3.bn.weight - torch.Size([1024]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.1.conv3.bn.bias - torch.Size([1024]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.2.conv1.conv.weight - torch.Size([256, 1024, 3, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.2.conv1.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.2.conv1.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.2.conv2.conv.weight - torch.Size([256, 256, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.2.conv2.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.2.conv2.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.2.conv3.conv.weight - torch.Size([1024, 256, 1, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.2.conv3.bn.weight - torch.Size([1024]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.2.conv3.bn.bias - torch.Size([1024]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.3.conv1.conv.weight - torch.Size([256, 1024, 3, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.3.conv1.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.3.conv1.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.3.conv2.conv.weight - torch.Size([256, 256, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.3.conv2.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.3.conv2.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.3.conv3.conv.weight - torch.Size([1024, 256, 1, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.3.conv3.bn.weight - torch.Size([1024]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.3.conv3.bn.bias - torch.Size([1024]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.4.conv1.conv.weight - torch.Size([256, 1024, 3, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.4.conv1.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.4.conv1.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.4.conv2.conv.weight - torch.Size([256, 256, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.4.conv2.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.4.conv2.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.4.conv3.conv.weight - torch.Size([1024, 256, 1, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.4.conv3.bn.weight - torch.Size([1024]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.4.conv3.bn.bias - torch.Size([1024]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.5.conv1.conv.weight - torch.Size([256, 1024, 3, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.5.conv1.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.5.conv1.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.5.conv2.conv.weight - torch.Size([256, 256, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.5.conv2.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.5.conv2.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.5.conv3.conv.weight - torch.Size([1024, 256, 1, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.5.conv3.bn.weight - torch.Size([1024]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3.5.conv3.bn.bias - torch.Size([1024]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer4.0.conv1.conv.weight - torch.Size([512, 1280, 3, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer4.0.conv1.bn.weight - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer4.0.conv1.bn.bias - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer4.0.conv2.conv.weight - torch.Size([512, 512, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer4.0.conv2.bn.weight - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer4.0.conv2.bn.bias - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer4.0.conv3.conv.weight - torch.Size([2048, 512, 1, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer4.0.conv3.bn.weight - torch.Size([2048]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer4.0.conv3.bn.bias - torch.Size([2048]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer4.0.downsample.conv.weight - torch.Size([2048, 1280, 1, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer4.0.downsample.bn.weight - torch.Size([2048]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer4.0.downsample.bn.bias - torch.Size([2048]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer4.1.conv1.conv.weight - torch.Size([512, 2048, 3, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer4.1.conv1.bn.weight - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer4.1.conv1.bn.bias - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer4.1.conv2.conv.weight - torch.Size([512, 512, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer4.1.conv2.bn.weight - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer4.1.conv2.bn.bias - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer4.1.conv3.conv.weight - torch.Size([2048, 512, 1, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer4.1.conv3.bn.weight - torch.Size([2048]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer4.1.conv3.bn.bias - torch.Size([2048]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer4.2.conv1.conv.weight - torch.Size([512, 2048, 3, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer4.2.conv1.bn.weight - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer4.2.conv1.bn.bias - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer4.2.conv2.conv.weight - torch.Size([512, 512, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer4.2.conv2.bn.weight - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer4.2.conv2.bn.bias - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer4.2.conv3.conv.weight - torch.Size([2048, 512, 1, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer4.2.conv3.bn.weight - torch.Size([2048]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer4.2.conv3.bn.bias - torch.Size([2048]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.conv1_lateral.conv.weight - torch.Size([16, 8, 5, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer1_lateral.conv.weight - torch.Size([64, 32, 5, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer2_lateral.conv.weight - torch.Size([128, 64, 5, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.slow_path.layer3_lateral.conv.weight - torch.Size([256, 128, 5, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.conv1.conv.weight - torch.Size([8, 3, 5, 7, 7]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.conv1.bn.weight - torch.Size([8]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.conv1.bn.bias - torch.Size([8]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer1.0.conv1.conv.weight - torch.Size([8, 8, 3, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer1.0.conv1.bn.weight - torch.Size([8]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer1.0.conv1.bn.bias - torch.Size([8]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer1.0.conv2.conv.weight - torch.Size([8, 8, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer1.0.conv2.bn.weight - torch.Size([8]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer1.0.conv2.bn.bias - torch.Size([8]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer1.0.conv3.conv.weight - torch.Size([32, 8, 1, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer1.0.conv3.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer1.0.conv3.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer1.0.downsample.conv.weight - torch.Size([32, 8, 1, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer1.0.downsample.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer1.0.downsample.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer1.1.conv1.conv.weight - torch.Size([8, 32, 3, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer1.1.conv1.bn.weight - torch.Size([8]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer1.1.conv1.bn.bias - torch.Size([8]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer1.1.conv2.conv.weight - torch.Size([8, 8, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer1.1.conv2.bn.weight - torch.Size([8]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer1.1.conv2.bn.bias - torch.Size([8]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer1.1.conv3.conv.weight - torch.Size([32, 8, 1, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer1.1.conv3.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer1.1.conv3.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer1.2.conv1.conv.weight - torch.Size([8, 32, 3, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer1.2.conv1.bn.weight - torch.Size([8]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer1.2.conv1.bn.bias - torch.Size([8]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer1.2.conv2.conv.weight - torch.Size([8, 8, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer1.2.conv2.bn.weight - torch.Size([8]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer1.2.conv2.bn.bias - torch.Size([8]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer1.2.conv3.conv.weight - torch.Size([32, 8, 1, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer1.2.conv3.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer1.2.conv3.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer2.0.conv1.conv.weight - torch.Size([16, 32, 3, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer2.0.conv1.bn.weight - torch.Size([16]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer2.0.conv1.bn.bias - torch.Size([16]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer2.0.conv2.conv.weight - torch.Size([16, 16, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer2.0.conv2.bn.weight - torch.Size([16]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer2.0.conv2.bn.bias - torch.Size([16]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer2.0.conv3.conv.weight - torch.Size([64, 16, 1, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer2.0.conv3.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer2.0.conv3.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer2.0.downsample.conv.weight - torch.Size([64, 32, 1, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer2.0.downsample.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer2.0.downsample.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer2.1.conv1.conv.weight - torch.Size([16, 64, 3, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer2.1.conv1.bn.weight - torch.Size([16]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer2.1.conv1.bn.bias - torch.Size([16]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer2.1.conv2.conv.weight - torch.Size([16, 16, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer2.1.conv2.bn.weight - torch.Size([16]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer2.1.conv2.bn.bias - torch.Size([16]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer2.1.conv3.conv.weight - torch.Size([64, 16, 1, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer2.1.conv3.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer2.1.conv3.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer2.2.conv1.conv.weight - torch.Size([16, 64, 3, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer2.2.conv1.bn.weight - torch.Size([16]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer2.2.conv1.bn.bias - torch.Size([16]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer2.2.conv2.conv.weight - torch.Size([16, 16, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer2.2.conv2.bn.weight - torch.Size([16]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer2.2.conv2.bn.bias - torch.Size([16]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer2.2.conv3.conv.weight - torch.Size([64, 16, 1, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer2.2.conv3.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer2.2.conv3.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer2.3.conv1.conv.weight - torch.Size([16, 64, 3, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer2.3.conv1.bn.weight - torch.Size([16]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer2.3.conv1.bn.bias - torch.Size([16]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer2.3.conv2.conv.weight - torch.Size([16, 16, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer2.3.conv2.bn.weight - torch.Size([16]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer2.3.conv2.bn.bias - torch.Size([16]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer2.3.conv3.conv.weight - torch.Size([64, 16, 1, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer2.3.conv3.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer2.3.conv3.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.0.conv1.conv.weight - torch.Size([32, 64, 3, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.0.conv1.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.0.conv1.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.0.conv2.conv.weight - torch.Size([32, 32, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.0.conv2.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.0.conv2.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.0.conv3.conv.weight - torch.Size([128, 32, 1, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.0.conv3.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.0.conv3.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.0.downsample.conv.weight - torch.Size([128, 64, 1, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.0.downsample.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.0.downsample.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.1.conv1.conv.weight - torch.Size([32, 128, 3, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.1.conv1.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.1.conv1.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.1.conv2.conv.weight - torch.Size([32, 32, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.1.conv2.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.1.conv2.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.1.conv3.conv.weight - torch.Size([128, 32, 1, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.1.conv3.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.1.conv3.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.2.conv1.conv.weight - torch.Size([32, 128, 3, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.2.conv1.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.2.conv1.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.2.conv2.conv.weight - torch.Size([32, 32, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.2.conv2.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.2.conv2.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.2.conv3.conv.weight - torch.Size([128, 32, 1, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.2.conv3.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.2.conv3.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.3.conv1.conv.weight - torch.Size([32, 128, 3, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.3.conv1.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.3.conv1.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.3.conv2.conv.weight - torch.Size([32, 32, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.3.conv2.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.3.conv2.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.3.conv3.conv.weight - torch.Size([128, 32, 1, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.3.conv3.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.3.conv3.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.4.conv1.conv.weight - torch.Size([32, 128, 3, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.4.conv1.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.4.conv1.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.4.conv2.conv.weight - torch.Size([32, 32, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.4.conv2.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.4.conv2.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.4.conv3.conv.weight - torch.Size([128, 32, 1, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.4.conv3.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.4.conv3.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.5.conv1.conv.weight - torch.Size([32, 128, 3, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.5.conv1.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.5.conv1.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.5.conv2.conv.weight - torch.Size([32, 32, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.5.conv2.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.5.conv2.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.5.conv3.conv.weight - torch.Size([128, 32, 1, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.5.conv3.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer3.5.conv3.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer4.0.conv1.conv.weight - torch.Size([64, 128, 3, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer4.0.conv1.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer4.0.conv1.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer4.0.conv2.conv.weight - torch.Size([64, 64, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer4.0.conv2.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer4.0.conv2.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer4.0.conv3.conv.weight - torch.Size([256, 64, 1, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer4.0.conv3.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer4.0.conv3.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer4.0.downsample.conv.weight - torch.Size([256, 128, 1, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer4.0.downsample.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer4.0.downsample.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer4.1.conv1.conv.weight - torch.Size([64, 256, 3, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer4.1.conv1.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer4.1.conv1.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer4.1.conv2.conv.weight - torch.Size([64, 64, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer4.1.conv2.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer4.1.conv2.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer4.1.conv3.conv.weight - torch.Size([256, 64, 1, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer4.1.conv3.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer4.1.conv3.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer4.2.conv1.conv.weight - torch.Size([64, 256, 3, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer4.2.conv1.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer4.2.conv1.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer4.2.conv2.conv.weight - torch.Size([64, 64, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer4.2.conv2.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer4.2.conv2.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer4.2.conv3.conv.weight - torch.Size([256, 64, 1, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer4.2.conv3.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

backbone.fast_path.layer4.2.conv3.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth 

roi_head.bbox_head.fc_cls.weight - torch.Size([81, 2304]): 
Initialized by user-defined `init_weights` in BBoxHeadAVA  

roi_head.bbox_head.fc_cls.bias - torch.Size([81]): 
Initialized by user-defined `init_weights` in BBoxHeadAVA  
2023/07/06 06:58:41 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
2023/07/06 06:58:41 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
2023/07/06 06:58:41 - mmengine - INFO - Checkpoints will be saved to /home/soumyadeep/mmaction_custom/mini_mmaction/work_dirs/slowfast_kinetics400-pretrained-r50_8xb16-4x16x1-20e_ava21-rgb.
2023/07/06 06:59:08 - mmengine - INFO - Epoch(train)  [1][ 20/382]  lr: 2.0000e-02  eta: 2:56:53  time: 1.3928  data_time: 0.2132  memory: 19433  grad_norm: 1.3135  loss: 0.2793  recall@thr=0.5: 0.2886  prec@thr=0.5: 0.4654  recall@top3: 0.5163  prec@top3: 0.4309  recall@top5: 0.7053  prec@top5: 0.3512  loss_action_cls: 0.2793
2023/07/06 06:59:29 - mmengine - INFO - Epoch(train)  [1][ 40/382]  lr: 2.0000e-02  eta: 2:32:58  time: 1.0224  data_time: 0.0293  memory: 19433  grad_norm: 0.5380  loss: 0.1434  recall@thr=0.5: 0.4315  prec@thr=0.5: 0.4435  recall@top3: 0.5874  prec@top3: 0.4624  recall@top5: 0.8239  prec@top5: 0.3806  loss_action_cls: 0.1434
